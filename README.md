# üßæ Receipt Processing Pipeline

> This project contains a set of scripts to perform a robust, multi-stage pipeline for extracting structured data from receipt images. It uses PaddleOCR for text recognition and a local Ollama-powered LLM for data parsing. The pipeline is designed to be resumable and can handle large datasets without crashing.

---
## ‚öôÔ∏è Scripts Overview

The pipeline is divided into three main scripts, which are orchestrated by a master script:

1.  **`run_ocr.py`**: Reads image files from an input directory, performs OCR to detect and extract text, and saves the raw text and metadata for each image into a corresponding output subfolder.

2.  **`run_llm.py`**: Reads the raw text files generated by the OCR script, sends the text to a local LLM for parsing, and saves the final structured data as a JSON file.

3.  **`extract_descriptions.py`**: A final utility script that scans all the final JSON outputs (including those in nested subdirectories) and aggregates every extracted item description into a single text file.

4.  **`run_all.py`**: The master script that automates the execution of the entire pipeline in the correct sequence for all specified datasets.

---
## ‚ñ∂Ô∏è How to Run

### Option 1: Run the Entire Pipeline Automatically (Recommended)

The `run_all.py` script is the simplest way to process your datasets. It provides a single point of control for the entire workflow.

**To run the full pipeline and automatically resume progress:**

```bash
python3 run_all.py
```

**To run the full pipeline from scratch (deletes all previous work):**

```bash
python3 run_all.py --override
```

### Option 2: Run Each Stage Manually

This gives you more granular control over each stage of the process.

#### Stage 1: OCR Processing

The `run_ocr.py` script takes a source image directory and a target output directory as arguments.

**To run or resume OCR on a dataset:**

```bash
python3 run_ocr.py path/to/input/images path/to/output/folder
```

**To start OCR from scratch (deletes previous OCR work):**

```bash
python3 run_ocr.py path/to/input/images path/to/output/folder --override
```

#### Stage 2: LLM Parsing

The `run_llm.py` script takes the directory of OCR outputs as its input.

**To run or resume LLM parsing:**

```bash
python3 run_llm.py path/to/output/folder
```

**To re-run only the LLM parsing (preserves OCR work):**

```bash
python3 run_llm.py path/to/output/folder --override
```

#### Stage 3: Description Extraction

The `extract_descriptions.py` script takes the main directory containing all your final outputs.

**To create the descriptions file:**

```bash
python3 extract_descriptions.py path/to/main/outputs
```

**To overwrite an existing descriptions file:**

```bash
python3 extract_descriptions.py path/to/main/outputs --override
```

---
## Command-Line Arguments Explained

### `run_ocr.py`

* `input_root` (Required): The first argument. The path to the folder containing the source receipt images.
* `output_root` (Required): The second argument. The path to the folder where the OCR output subfolders will be created.
* `--override` (Optional): A flag. If present, it will delete the entire `output_root` directory before starting. If omitted, it will check for existing `raw_output.txt` files and skip any images that have already been processed.

### `run_llm.py`

* `dir` (Required): The first argument. The path to the folder containing the OCR output subfolders (e.g., `final_outputs/SROIE2019`).
* `--override` (Optional): A flag. If present, it will delete all existing `final_extracted_data.json` files within the directory, allowing you to re-run the LLM parsing on the existing OCR text. If omitted, it will only process folders that do not already have a final JSON file.

### `extract_descriptions.py`

* `dir` (Required): The first argument. The path to the main outputs folder containing all dataset subdirectories. The script automatically searches through all nested folders within this directory.
* `output_file` (Optional): The second argument. The name of the final text file. Defaults to `item_descriptions.txt`.
* `--override` (Optional): A flag. If the `output_file` already exists, the script will stop unless this flag is provided.

### `run_all.py`

* `--override` (Optional): A flag. If present, it will pass the `--override` flag to all three underlying scripts, effectively starting the entire pipeline from scratch. If omitted, each stage will attempt to resume progress.
